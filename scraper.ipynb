{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ab4b559",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Failed to download https://www.gettyimages.in/components/global-nav/static/static/GettyHeaderLogo-4c344fa4f9e47c257bea.svg\n",
      "Failed to download https://www.gettyimages.in/components/global-nav/static/static/UnsplashForBrands-00c7af5aed68b4b7f3f3.svg\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import time\n",
    "import requests\n",
    "import cv2 as cv\n",
    "import numpy np\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.chrome.service import Service as ChromeService\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.chrome.options import Options\n",
    "from webdriver_manager.chrome import ChromeDriverManager\n",
    "from bs4 import BeautifulSoup\n",
    "from urllib.parse import urljoin\n",
    "\n",
    "def download_image(url):\n",
    "    try:\n",
    "        response = requests.get(url, stream=True)\n",
    "        if response.status_code == 200:\n",
    "            return response.content\n",
    "        else:\n",
    "            print(f\"Failed to download {url}\")\n",
    "            return None\n",
    "    except Exception as e:\n",
    "        print(f\"Error downloading {url}: {e}\")\n",
    "        return None\n",
    "\n",
    "def detect_and_save_first_face(image_data, output_folder, file_name):\n",
    "    image_array = np.frombuffer(image_data, np.uint8)\n",
    "    img = cv.imdecode(image_array, cv.IMREAD_COLOR)\n",
    "\n",
    "    if img is None:\n",
    "        print(f\"Error: Could not process image {file_name}.\")\n",
    "        return False\n",
    "\n",
    "    classifier = cv.CascadeClassifier(cv.data.haarcascades + 'haarcascade_frontalface_default.xml')\n",
    "\n",
    "    faces = classifier.detectMultiScale(img, scaleFactor=1.1, minNeighbors=4, minSize=(30, 30))\n",
    "\n",
    "    if len(faces) == 0:\n",
    "        print(f\"No faces detected in {file_name}.\")\n",
    "        return False\n",
    "\n",
    "    if not os.path.exists(output_folder):\n",
    "        os.makedirs(output_folder)\n",
    "\n",
    "    (x, y, w, h) = faces[0]\n",
    "    face = img[max(0, y-25):min(y+h+20, img.shape[0]), max(0, x-25):min(x+w+20, img.shape[1])]\n",
    "\n",
    "    save_path = os.path.join(output_folder, file_name)\n",
    "    cv.imwrite(save_path, face)\n",
    "    print(f\"{save_path} is exported with detected face.\")\n",
    "    return True\n",
    "\n",
    "def scrape_and_save_images_with_faces(url, output_folder, num_pages=5):\n",
    "    chrome_options = Options()\n",
    "    chrome_options.add_argument(\"--headless\")\n",
    "    driver = webdriver.Chrome(service=ChromeService(ChromeDriverManager().install()), options=chrome_options)\n",
    "\n",
    "    for page in range(1, num_pages + 1):\n",
    "        page_url = f\"{url}?page={page}\"\n",
    "        driver.get(page_url)\n",
    "        \n",
    "        time.sleep(1)\n",
    "        \n",
    "        soup = BeautifulSoup(driver.page_source, 'html.parser')\n",
    "\n",
    "        img_tags = soup.find_all('img')\n",
    "\n",
    "        for img in img_tags:\n",
    "            img_url = img.get('src')\n",
    "            if not img_url:\n",
    "                continue\n",
    "\n",
    "            img_url = urljoin(url, img_url)\n",
    "\n",
    "            img_name = os.path.basename(img_url).split(\"?\")[0]\n",
    "\n",
    "            image_data = download_image(img_url)\n",
    "            if image_data is None:\n",
    "                continue\n",
    "\n",
    "            detect_and_save_first_face(image_data, output_folder, img_name)\n",
    "        \n",
    "        print(f\"Completed processing page {page}\")\n",
    "        print('-*-'*20)\n",
    "        print('\\n')\n",
    "        print('-*-'*20)\n",
    "    \n",
    "    driver.quit()\n",
    "\n",
    "def main():\n",
    "    webpage_url = 'https://www.gettyimages.in/photos/akshay-kumar-photo'\n",
    "    output_folder = 'Extracted_faces' + ' ' + str(webpage_url.split('/')[-1])\n",
    "    num_pages_to_scrape = 30\n",
    "\n",
    "    scrape_and_save_images_with_faces(webpage_url, output_folder, num_pages=num_pages_to_scrape)\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "616c3217",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
